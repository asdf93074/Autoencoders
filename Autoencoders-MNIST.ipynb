{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f9cfe8-b2fb-4ce7-99bb-8aa90883acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7383561ff050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b773fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ab7f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/.local/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_complete_set = torchvision.datasets.MNIST('./datasets', train=True, transform=transforms, download=True)\n",
    "train_set, val_set = random_split(train_complete_set, [0.95, 0.05], torch.Generator().manual_seed(42))\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('./datasets', train=False, transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa67812",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f689a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, model, lr=1e-1, reg=0.0, optim=torch.optim.Adam, batch_size=batch_size, criterion=nn.CrossEntropyLoss, print_every=100):\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.optim = optim(model.parameters(), lr=lr, weight_decay=reg)\n",
    "        self.criterion = criterion()\n",
    "        self.dataloaders = {}\n",
    "        self.loss_history = []\n",
    "        self.print_every = print_every\n",
    "\n",
    "        self.anneal_counter = 0\n",
    "        self.last_anneal_idx = 0\n",
    "        self.max_anneal_count = 3\n",
    "\n",
    "    def set_data_loader(self, loader, split):\n",
    "        self.dataloaders[split] = loader\n",
    "\n",
    "    def estimate_loss(self, split):\n",
    "        dataloader = self.dataloaders[split]\n",
    "\n",
    "        if dataloader == None:\n",
    "            return -1.0\n",
    "\n",
    "        self.model.eval()\n",
    "        avg_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloader):\n",
    "                if i % 5000 == 0 and i > 0:\n",
    "                    break\n",
    "                images, _ = data\n",
    "                N = images.shape[0]\n",
    "                images = images.to(device)\n",
    "\n",
    "                logits = self.model(images)\n",
    "                loss = self.criterion(logits, images.reshape(N, -1))\n",
    "                avg_loss += loss.item()\n",
    "\n",
    "        self.model.train()\n",
    "        return avg_loss / len(dataloader)\n",
    "    \n",
    "    def anneal_learning_rate(self):\n",
    "        num_losses = len(self.loss_history)\n",
    "        if (self.anneal_counter == self.max_anneal_count\n",
    "            or num_losses < 3\n",
    "            or num_losses - self.last_anneal_idx < 3):\n",
    "            return\n",
    "\n",
    "        train = [l[0] for l in self.loss_history]\n",
    "        arr = np.array(train[-3:])\n",
    "        if arr.std() >= 1e-4:\n",
    "            return\n",
    "\n",
    "        self.last_anneal_idx = num_losses\n",
    "        self.anneal_counter += 1\n",
    "        print(f\"Annealing learning_rate {self.lr} by 10. New learning rate {self.lr / 10}. Anneal count {self.anneal_counter} / {self.max_anneal_count}.\")\n",
    "        self.lr /= 10\n",
    "\n",
    "    def train(self, loader, epochs=1):\n",
    "        for e in range(epochs):\n",
    "            for i, data in enumerate(loader):\n",
    "                if i % self.print_every == 0 and i > 0:\n",
    "                    train_loss = self.estimate_loss('train')\n",
    "                    val_loss = self.estimate_loss('val')\n",
    "                    \n",
    "                    print(f\"epoch: {e} iter: {i} train_loss: {train_loss} val_loss: {val_loss}\")\n",
    "\n",
    "                    self.loss_history.append((train_loss, val_loss))\n",
    "                    self.anneal_learning_rate()\n",
    "\n",
    "                images, _ = data\n",
    "                N = images.shape[0]\n",
    "                images = images.to(device)\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                logits = self.model(images)\n",
    "                loss = self.criterion(logits, images.reshape(N, -1))\n",
    "                loss.backward()\n",
    "                self.optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2334e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_chananels = out_channels\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 512, device=device),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 256, device=device),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, out_channels, device=device),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels, 256, device=device),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 512, device=device),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, in_channels, device=device),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(self.encoder(x))\n",
    "        return x\n",
    "    \n",
    "    def decode(self, embd):\n",
    "        assert(embd.shape[1] == self.out_chananels)\n",
    "\n",
    "        return self.decoder(embd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1338bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for out_channels = 10, learning_rate = 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 iter: 100 train_loss: 0.11187696921317566 val_loss: 0.11160884983837605\n",
      "epoch: 0 iter: 200 train_loss: 0.1118825992126636 val_loss: 0.11164152373870213\n",
      "epoch: 1 iter: 100 train_loss: 0.11187295953120886 val_loss: 0.11157132374743621\n",
      "Annealing learning_rate 0.1 by half. New learning rate 0.05.\n",
      "epoch: 1 iter: 200 train_loss: 0.11187441022273137 val_loss: 0.11156562405327956\n",
      "epoch: 2 iter: 100 train_loss: 0.1118759114980163 val_loss: 0.1116947711755832\n",
      "epoch: 2 iter: 200 train_loss: 0.11186753544171295 val_loss: 0.11160295270383358\n",
      "Annealing learning_rate 0.05 by half. New learning rate 0.025.\n",
      "epoch: 3 iter: 100 train_loss: 0.11187256992932393 val_loss: 0.11163564523061116\n",
      "epoch: 3 iter: 200 train_loss: 0.11188117899167697 val_loss: 0.11153959420820077\n",
      "epoch: 4 iter: 100 train_loss: 0.111882129926318 val_loss: 0.1115666205684344\n",
      "Annealing learning_rate 0.025 by half. New learning rate 0.0125.\n",
      "epoch: 4 iter: 200 train_loss: 0.11187180482485903 val_loss: 0.11148591339588165\n",
      "epoch: 5 iter: 100 train_loss: 0.11187480590535921 val_loss: 0.11158914491534233\n",
      "epoch: 5 iter: 200 train_loss: 0.11188178960517918 val_loss: 0.11154623950521152\n",
      "epoch: 6 iter: 100 train_loss: 0.11187719156121993 val_loss: 0.11163252840439479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m solver\u001b[38;5;241m.\u001b[39mset_data_loader(train_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m solver\u001b[38;5;241m.\u001b[39mset_data_loader(val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m losses[(out, lr)] \u001b[38;5;241m=\u001b[39m [solver\u001b[38;5;241m.\u001b[39mloss_history, model]\n",
      "Cell \u001b[0;32mIn[60], line 63\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self, loader, epochs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_loss(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[60], line 28\u001b[0m, in \u001b[0;36mSolver.estimate_loss\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m     26\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "out_channels = [10, 20, 30, 40, 50, 64]\n",
    "epochs = 10\n",
    "learning_rates = [1e-1, 1e-2, 3e-3, 3e-4, 4e-5]\n",
    "\n",
    "losses = {}\n",
    "for out, lr in product(out_channels, learning_rates):\n",
    "    print(f\"Training for out_channels = {out}, learning_rate = {lr}\")\n",
    "    model = Net(784, out)\n",
    "    solver = Solver(model, lr=lr, batch_size=batch_size, criterion=nn.MSELoss)\n",
    "    solver.set_data_loader(train_loader, 'train')\n",
    "    solver.set_data_loader(val_loader, 'val')\n",
    "\n",
    "    solver.train(train_loader, epochs)\n",
    "\n",
    "    losses[(out, lr)] = [solver.loss_history, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2bef632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for out_channels = 20, learning_rate = 0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 iter: 100 train_loss: 0.048963829357126905 val_loss: 0.048639168652395405\n",
      "epoch: 0 iter: 200 train_loss: 0.030726292400282594 val_loss: 0.030523389888306458\n",
      "epoch: 1 iter: 100 train_loss: 0.022024644588876197 val_loss: 0.022031101242949564\n",
      "epoch: 1 iter: 200 train_loss: 0.018530718347416864 val_loss: 0.018699262135972578\n",
      "Annealing learning_rate 0.003 by half. New learning rate 0.0015.\n",
      "epoch: 2 iter: 100 train_loss: 0.015461539824580933 val_loss: 0.015721528014789026\n",
      "epoch: 2 iter: 200 train_loss: 0.013764013331634047 val_loss: 0.014025277458131313\n",
      "epoch: 3 iter: 100 train_loss: 0.012211656957998404 val_loss: 0.012572066159918904\n",
      "Annealing learning_rate 0.0015 by half. New learning rate 0.00075.\n",
      "epoch: 3 iter: 200 train_loss: 0.010940387310468562 val_loss: 0.011308661041160425\n",
      "epoch: 4 iter: 100 train_loss: 0.010065553935386674 val_loss: 0.010432497132569551\n",
      "epoch: 4 iter: 200 train_loss: 0.009526308909927249 val_loss: 0.009928293448562423\n",
      "Annealing learning_rate 0.00075 by half. New learning rate 0.000375.\n",
      "epoch: 5 iter: 100 train_loss: 0.008914095771419628 val_loss: 0.009338982480888566\n",
      "epoch: 5 iter: 200 train_loss: 0.008779458196274102 val_loss: 0.00921596004627645\n",
      "epoch: 6 iter: 100 train_loss: 0.008280694595383555 val_loss: 0.008727935065204898\n",
      "epoch: 6 iter: 200 train_loss: 0.008183542363379034 val_loss: 0.008647302708898982\n",
      "epoch: 7 iter: 100 train_loss: 0.007852191113837632 val_loss: 0.008394050877541304\n",
      "epoch: 7 iter: 200 train_loss: 0.007568477400298744 val_loss: 0.008066297275945544\n",
      "epoch: 8 iter: 100 train_loss: 0.0073903194135848446 val_loss: 0.007977379641185204\n",
      "epoch: 8 iter: 200 train_loss: 0.007176487877831331 val_loss: 0.007787056538897256\n",
      "epoch: 9 iter: 100 train_loss: 0.0071267249801868545 val_loss: 0.007766750059090555\n",
      "epoch: 9 iter: 200 train_loss: 0.00707469674269982 val_loss: 0.007705961276466648\n",
      "epoch: 10 iter: 100 train_loss: 0.006826219883968744 val_loss: 0.007500047291008134\n",
      "epoch: 10 iter: 200 train_loss: 0.006674220042111093 val_loss: 0.0073768350994214416\n",
      "epoch: 11 iter: 100 train_loss: 0.006640690802742681 val_loss: 0.007363192892322938\n",
      "epoch: 11 iter: 200 train_loss: 0.006577834411787345 val_loss: 0.007318193791434169\n",
      "epoch: 12 iter: 100 train_loss: 0.006389636262382627 val_loss: 0.007175317538591723\n",
      "epoch: 12 iter: 200 train_loss: 0.00639084824298262 val_loss: 0.007132518221624196\n",
      "epoch: 13 iter: 100 train_loss: 0.006347314458791451 val_loss: 0.007149985254121323\n",
      "epoch: 13 iter: 200 train_loss: 0.006142075025296933 val_loss: 0.006939492110783855\n",
      "epoch: 14 iter: 100 train_loss: 0.00606472043512648 val_loss: 0.006908932235091925\n",
      "epoch: 14 iter: 200 train_loss: 0.005982349280084195 val_loss: 0.006805616741379102\n",
      "epoch: 15 iter: 100 train_loss: 0.006057105622266841 val_loss: 0.00690641157173862\n",
      "epoch: 15 iter: 200 train_loss: 0.0060136618756693305 val_loss: 0.006887368042953312\n",
      "epoch: 16 iter: 100 train_loss: 0.0058469024670598484 val_loss: 0.006711550018129249\n",
      "epoch: 16 iter: 200 train_loss: 0.0061501446409744 val_loss: 0.007041788815210263\n",
      "epoch: 17 iter: 100 train_loss: 0.00576046571310927 val_loss: 0.006675062196639677\n",
      "epoch: 17 iter: 200 train_loss: 0.00576292038498438 val_loss: 0.006704755942337215\n",
      "epoch: 18 iter: 100 train_loss: 0.005783380399721219 val_loss: 0.00672297067164133\n",
      "epoch: 18 iter: 200 train_loss: 0.005720760147066395 val_loss: 0.006670327934746941\n",
      "epoch: 19 iter: 100 train_loss: 0.005628957150027891 val_loss: 0.006608779270512362\n",
      "epoch: 19 iter: 200 train_loss: 0.005692620110184355 val_loss: 0.006669699563644826\n",
      "epoch: 20 iter: 100 train_loss: 0.005508460210962012 val_loss: 0.006512534416591127\n",
      "epoch: 20 iter: 200 train_loss: 0.005476822836466568 val_loss: 0.0064809584291651845\n",
      "epoch: 21 iter: 100 train_loss: 0.0055001504644083335 val_loss: 0.006534519838169217\n",
      "epoch: 21 iter: 200 train_loss: 0.005523268043610681 val_loss: 0.006534782160694401\n",
      "epoch: 22 iter: 100 train_loss: 0.005400471550082546 val_loss: 0.006444951985031366\n",
      "epoch: 22 iter: 200 train_loss: 0.0053338390971312604 val_loss: 0.0063981768519928055\n",
      "epoch: 23 iter: 100 train_loss: 0.00561216271444821 val_loss: 0.006667196013343831\n",
      "epoch: 23 iter: 200 train_loss: 0.005271312097847596 val_loss: 0.0063507575541734695\n",
      "epoch: 24 iter: 100 train_loss: 0.005223525381091598 val_loss: 0.006319086571844916\n",
      "epoch: 24 iter: 200 train_loss: 0.00539512534922348 val_loss: 0.006476840858037273\n",
      "epoch: 25 iter: 100 train_loss: 0.005165836372884667 val_loss: 0.006266618884789447\n",
      "epoch: 25 iter: 200 train_loss: 0.005267369970178123 val_loss: 0.006398127259065707\n",
      "epoch: 26 iter: 100 train_loss: 0.0053308228899478375 val_loss: 0.0064689816208556294\n",
      "epoch: 26 iter: 200 train_loss: 0.005175648904468179 val_loss: 0.006297469643565516\n",
      "epoch: 27 iter: 100 train_loss: 0.005195989398778554 val_loss: 0.006359711444626252\n",
      "epoch: 27 iter: 200 train_loss: 0.005092089807806796 val_loss: 0.00627065438311547\n",
      "epoch: 28 iter: 100 train_loss: 0.005078359999831749 val_loss: 0.006265898623193304\n",
      "epoch: 28 iter: 200 train_loss: 0.005094221225133659 val_loss: 0.006256668207546075\n",
      "epoch: 29 iter: 100 train_loss: 0.005159366274494761 val_loss: 0.006369060991952817\n",
      "epoch: 29 iter: 200 train_loss: 0.005081615506800835 val_loss: 0.006264991941861808\n",
      "epoch: 30 iter: 100 train_loss: 0.00500961897619102 val_loss: 0.006258376835224529\n",
      "epoch: 30 iter: 200 train_loss: 0.004996532994017607 val_loss: 0.006189608636001746\n",
      "epoch: 31 iter: 100 train_loss: 0.0050001711764210005 val_loss: 0.006230434014772375\n",
      "epoch: 31 iter: 200 train_loss: 0.005030524052445664 val_loss: 0.00626907388990124\n",
      "epoch: 32 iter: 100 train_loss: 0.004982328779510986 val_loss: 0.006254755736639102\n",
      "epoch: 32 iter: 200 train_loss: 0.00508347464174099 val_loss: 0.00634427535502861\n",
      "epoch: 33 iter: 100 train_loss: 0.004913746283260162 val_loss: 0.006203832376437883\n",
      "epoch: 33 iter: 200 train_loss: 0.00490305287295727 val_loss: 0.006184635140622656\n",
      "epoch: 34 iter: 100 train_loss: 0.004909979530313625 val_loss: 0.006217815214768052\n",
      "epoch: 34 iter: 200 train_loss: 0.0049499466058885834 val_loss: 0.006190854823216796\n",
      "epoch: 35 iter: 100 train_loss: 0.004892650457107433 val_loss: 0.006214890046976507\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m solver\u001b[38;5;241m.\u001b[39mset_data_loader(train_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m solver\u001b[38;5;241m.\u001b[39mset_data_loader(val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m losses[(out, lr)] \u001b[38;5;241m=\u001b[39m [solver\u001b[38;5;241m.\u001b[39mloss_history, best_model]\n",
      "Cell \u001b[0;32mIn[60], line 63\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self, loader, epochs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_loss(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[60], line 28\u001b[0m, in \u001b[0;36mSolver.estimate_loss\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m     26\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = 20\n",
    "lr = 3e-3\n",
    "epochs = 50\n",
    "\n",
    "print(f\"Training for out_channels = {out}, learning_rate = {lr}\")\n",
    "best_model = Net(784, out)\n",
    "solver = Solver(best_model, lr=lr, batch_size=batch_size, criterion=nn.MSELoss)\n",
    "solver.set_data_loader(train_loader, 'train')\n",
    "solver.set_data_loader(val_loader, 'val')\n",
    "\n",
    "solver.train(train_loader, epochs)\n",
    "\n",
    "losses[(out, lr)] = [solver.loss_history, best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34326605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7cf526208c80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbbUlEQVR4nO3df3BV9f3n8ddNSC6oyU1DTG5SAk1QwQrELUKaohRKhiTddUGYXfzxB7gsLDa4Ymp10lHRtrNpcZY6uinOzlbQGVGLKzA636WFaMLQJvglyjJMNSVpWvBLEpR+kxuChEA++wfrba8E8VzuzTs3PB8zZ4bce945H09veXKSmxOfc84JAIBhlmS9AADA1YkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE2OsF/BFg4ODOn78uNLS0uTz+ayXAwDwyDmn3t5e5eXlKSnp0tc5Iy5Ax48fV35+vvUyAABX6NixY5owYcIlnx9xAUpLS5Mk3a7va4xSjFcDAPDqnAa0T/8U/vv8UuIWoNraWj3zzDPq7OxUUVGRnn/+ec2ePfuyc59/2W2MUjTGR4AAIOH8/zuMXu7bKHF5E8Lrr7+uqqoqrV+/Xu+//76KiopUVlamEydOxONwAIAEFJcAbdy4UatWrdL999+vb37zm3rhhRd0zTXX6MUXX4zH4QAACSjmATp79qyam5tVWlr694MkJam0tFSNjY0X7d/f369QKBSxAQBGv5gH6NNPP9X58+eVk5MT8XhOTo46Ozsv2r+mpkaBQCC88Q44ALg6mP8ganV1tXp6esLbsWPHrJcEABgGMX8XXFZWlpKTk9XV1RXxeFdXl4LB4EX7+/1++f3+WC8DADDCxfwKKDU1VTNnzlRdXV34scHBQdXV1amkpCTWhwMAJKi4/BxQVVWVli9frttuu02zZ8/Ws88+q76+Pt1///3xOBwAIAHFJUDLli3TJ598oieffFKdnZ269dZbtWvXrovemAAAuHr5nHPOehH/KBQKKRAIaJ4WcScEAEhA59yA6rVTPT09Sk9Pv+R+5u+CAwBcnQgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImYB+ipp56Sz+eL2KZOnRrrwwAAEtyYeHzSW265RXv27Pn7QcbE5TAAgAQWlzKMGTNGwWAwHp8aADBKxOV7QEeOHFFeXp4KCwt133336ejRo5fct7+/X6FQKGIDAIx+MQ9QcXGxtmzZol27dmnTpk1qb2/XHXfcod7e3iH3r6mpUSAQCG/5+fmxXhIAYATyOedcPA/Q3d2tSZMmaePGjVq5cuVFz/f396u/vz/8cSgUUn5+vuZpkcb4UuK5NABAHJxzA6rXTvX09Cg9Pf2S+8X93QEZGRm66aab1NraOuTzfr9ffr8/3ssAAIwwcf85oFOnTqmtrU25ubnxPhQAIIHEPECPPPKIGhoa9Je//EV/+MMfdNdddyk5OVn33HNPrA8FAEhgMf8S3Mcff6x77rlHJ0+e1PXXX6/bb79dTU1Nuv7662N9KABAAot5gF577bVYf0oAwCjEveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNx/4V0iN6fNs/0PDO98F88z/Q/lu15RpLUdCi6OeAKjMkNep4519EZh5XgSnEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcDXuYHP/RdzzP/HPpM55n0pJSPc/cWv6Q5xlJmtgU1RgQdvquYs8zPctDnmd6P53geUaSbvrPB6Kaw1fDFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQ6TU5PPeZ6J5saiez5L8zzzjTf+5nlGkgajmsJwSho7Nqq53n9b5HnmX/6d99f4P5du9DwTzf8v7v/LQs8zknQyqil8VVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBnpMLl5o/fbGv65fMDzTOm4Xs8zndvqPc9I0v/+99/xPHP+yJ+jOtZIlpwR8DzTO3+q55kTt3n/9+Ks+R96npGkHZP+h+eZpCj+PTso7zcWxejBFRAAwAQBAgCY8BygvXv36s4771ReXp58Pp927NgR8bxzTk8++aRyc3M1btw4lZaW6siRI7FaLwBglPAcoL6+PhUVFam2tnbI5zds2KDnnntOL7zwgvbv369rr71WZWVlOnPmzBUvFgAwenh+E0JFRYUqKiqGfM45p2effVaPP/64Fi1aJEl6+eWXlZOTox07dujuu+++stUCAEaNmH4PqL29XZ2dnSotLQ0/FggEVFxcrMbGxiFn+vv7FQqFIjYAwOgX0wB1dnZKknJyciIez8nJCT/3RTU1NQoEAuEtPz8/lksCAIxQ5u+Cq66uVk9PT3g7duyY9ZIAAMMgpgEKBoOSpK6urojHu7q6ws99kd/vV3p6esQGABj9YhqggoICBYNB1dXVhR8LhULav3+/SkpKYnkoAECC8/wuuFOnTqm1tTX8cXt7uw4ePKjMzExNnDhR69at089+9jPdeOONKigo0BNPPKG8vDwtXrw4lusGACQ4zwE6cOCA5s+fH/64qqpKkrR8+XJt2bJFjz76qPr6+rR69Wp1d3fr9ttv165duzR27NjYrRoAkPB8zjlnvYh/FAqFFAgENE+LNMaXYr0cU3968TbPMx+VbYrDSoa274z3f1T8388mxWEltrLGeP/RgWVpHXFYia2b9/wXzzPPz9nqeSaaG+5O/d0azzOSdNP9zVHNXe3OuQHVa6d6enq+9Pv65u+CAwBcnQgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jwPCZ+lCL55mb/9tazzPvLd7oeUaS5o1N9jwzd+yRqI41kqX4vJ+HD88OeJ75P6emeZ7Z97fJnmck6dP/XuB55sad73meeb1xtueZ7+b/zvNM7q6r+876IxVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GOoIN9vZ6nrnxwf2eZ/7jzv/qeUaSeiemeh9acjKqYw2Xf/1wvOeZvN+f9zwzrvOM5xk1HfI+o0+imJHGRTGXfMsUzzOP5L7keebRjnmeZ9Jeb/I8g/jjCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSKGUPc1RzWVGM/RiVIcaNlH9N0GSlPPr455npqQke5753d5bPc9MFjcjHYm4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUgAXSb6x0PPM/8zf5nlm0POElL/7fBRTGIm4AgIAmCBAAAATngO0d+9e3XnnncrLy5PP59OOHTsinl+xYoV8Pl/EVl5eHqv1AgBGCc8B6uvrU1FRkWpray+5T3l5uTo6OsLbq6++ekWLBACMPp7fhFBRUaGKioov3cfv9ysYDEa9KADA6BeX7wHV19crOztbU6ZM0QMPPKCTJ09ect/+/n6FQqGIDQAw+sU8QOXl5Xr55ZdVV1enX/ziF2poaFBFRYXOnx/6rZM1NTUKBALhLT8/P9ZLAgCMQDH/OaC77747/Ofp06drxowZmjx5surr67VgwYKL9q+urlZVVVX441AoRIQA4CoQ97dhFxYWKisrS62trUM+7/f7lZ6eHrEBAEa/uAfo448/1smTJ5WbmxvvQwEAEojnL8GdOnUq4mqmvb1dBw8eVGZmpjIzM/X0009r6dKlCgaDamtr06OPPqobbrhBZWVlMV04ACCxeQ7QgQMHNH/+/PDHn3//Zvny5dq0aZMOHTqkl156Sd3d3crLy9PChQv105/+VH6/P3arBgAkPM8Bmjdvnpxzl3z+t7/97RUtCIC9lvWBYTnO1LcqPc9MqTvoeebSf2PBEveCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImY/0puACPH6buKo5r7aP6vPM/0DJ7xPFPwxnnPM27grOcZjExcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKTCKdU9OjmpuUIOeZ/7DR/d6nknd0+x5BqMHV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgokiOSMgOeZ+1fsisNKhjZ2yd88z3i/5SlGE66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUSBADRYWeZyq/tieqY+35LM3zzGBvb1THwtWLKyAAgAkCBAAw4SlANTU1mjVrltLS0pSdna3FixerpaUlYp8zZ86osrJS48eP13XXXaelS5eqq6srposGACQ+TwFqaGhQZWWlmpqatHv3bg0MDGjhwoXq6+sL7/Pwww/rrbfe0rZt29TQ0KDjx49ryZIlMV84ACCxeXoTwq5dkb9dccuWLcrOzlZzc7Pmzp2rnp4e/frXv9bWrVv1ve99T5K0efNm3XzzzWpqatK3v/3t2K0cAJDQruh7QD09PZKkzMxMSVJzc7MGBgZUWloa3mfq1KmaOHGiGhsbh/wc/f39CoVCERsAYPSLOkCDg4Nat26d5syZo2nTpkmSOjs7lZqaqoyMjIh9c3Jy1NnZOeTnqampUSAQCG/5+fnRLgkAkECiDlBlZaUOHz6s11577YoWUF1drZ6envB27NixK/p8AIDEENUPoq5du1Zvv/229u7dqwkTJoQfDwaDOnv2rLq7uyOugrq6uhQMBof8XH6/X36/P5plAAASmKcrIOec1q5dq+3bt+udd95RQUFBxPMzZ85USkqK6urqwo+1tLTo6NGjKikpic2KAQCjgqcroMrKSm3dulU7d+5UWlpa+Ps6gUBA48aNUyAQ0MqVK1VVVaXMzEylp6frwQcfVElJCe+AAwBE8BSgTZs2SZLmzZsX8fjmzZu1YsUKSdIvf/lLJSUlaenSperv71dZWZl+9atfxWSxAIDRw1OAnHOX3Wfs2LGqra1VbW1t1IsCcLE/Lxq+75U+9r/+k+eZr+sPcVgJRjPuBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATUf1GVADDr7i4xfPMS6FJUR1r0kt/9jxzLqoj4WrGFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQIJojK3zvNMbceCqI51rqMzqjnAC66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUMPCvy0s8z/yb1PfisBLADldAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKGOiu6PM8k+zzxWElgB2ugAAAJggQAMCEpwDV1NRo1qxZSktLU3Z2thYvXqyWlpaIfebNmyefzxexrVmzJqaLBgAkPk8BamhoUGVlpZqamrR7924NDAxo4cKF6uuL/Hr2qlWr1NHREd42bNgQ00UDABKfpzch7Nq1K+LjLVu2KDs7W83NzZo7d2748WuuuUbBYDA2KwQAjEpX9D2gnp4eSVJmZmbE46+88oqysrI0bdo0VVdX6/Tp05f8HP39/QqFQhEbAGD0i/pt2IODg1q3bp3mzJmjadOmhR+/9957NWnSJOXl5enQoUN67LHH1NLSojfffHPIz1NTU6Onn3462mUAABJU1AGqrKzU4cOHtW/fvojHV69eHf7z9OnTlZubqwULFqitrU2TJ0++6PNUV1erqqoq/HEoFFJ+fn60ywIAJIioArR27Vq9/fbb2rt3ryZMmPCl+xYXF0uSWltbhwyQ3++X3++PZhkAgATmKUDOOT344IPavn276uvrVVBQcNmZgwcPSpJyc3OjWiAAYHTyFKDKykpt3bpVO3fuVFpamjo7OyVJgUBA48aNU1tbm7Zu3arvf//7Gj9+vA4dOqSHH35Yc+fO1YwZM+LyHwAASEyeArRp0yZJF37Y9B9t3rxZK1asUGpqqvbs2aNnn31WfX19ys/P19KlS/X444/HbMEAgNHB85fgvkx+fr4aGhquaEEAgKsDd8MGDGS/Mc7zzCff6fc80/inQs8zknSTmqOaA7zgZqQAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgoYuPaN/Z5nVr5xu+cZbiqKkYwrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZG3L3gnHOSpHMakJzxYgAAnp3TgKS//31+KSMuQL29vZKkffon45UAAK5Eb2+vAoHAJZ/3ucslapgNDg7q+PHjSktLk8/ni3guFAopPz9fx44dU3p6utEK7XEeLuA8XMB5uIDzcMFIOA/OOfX29iovL09JSZf+Ts+IuwJKSkrShAkTvnSf9PT0q/oF9jnOwwWchws4DxdwHi6wPg9fduXzOd6EAAAwQYAAACYSKkB+v1/r16+X3++3XoopzsMFnIcLOA8XcB4uSKTzMOLehAAAuDok1BUQAGD0IEAAABMECABgggABAEwkTIBqa2v1jW98Q2PHjlVxcbHee+896yUNu6eeeko+ny9imzp1qvWy4m7v3r268847lZeXJ5/Ppx07dkQ875zTk08+qdzcXI0bN06lpaU6cuSIzWLj6HLnYcWKFRe9PsrLy20WGyc1NTWaNWuW0tLSlJ2drcWLF6ulpSVinzNnzqiyslLjx4/Xddddp6VLl6qrq8toxfHxVc7DvHnzLno9rFmzxmjFQ0uIAL3++uuqqqrS+vXr9f7776uoqEhlZWU6ceKE9dKG3S233KKOjo7wtm/fPuslxV1fX5+KiopUW1s75PMbNmzQc889pxdeeEH79+/Xtddeq7KyMp05c2aYVxpflzsPklReXh7x+nj11VeHcYXx19DQoMrKSjU1NWn37t0aGBjQwoUL1dfXF97n4Ycf1ltvvaVt27apoaFBx48f15IlSwxXHXtf5TxI0qpVqyJeDxs2bDBa8SW4BDB79mxXWVkZ/vj8+fMuLy/P1dTUGK5q+K1fv94VFRVZL8OUJLd9+/bwx4ODgy4YDLpnnnkm/Fh3d7fz+/3u1VdfNVjh8PjieXDOueXLl7tFixaZrMfKiRMnnCTX0NDgnLvwv31KSorbtm1beJ8PP/zQSXKNjY1Wy4y7L54H55z77ne/6x566CG7RX0FI/4K6OzZs2publZpaWn4saSkJJWWlqqxsdFwZTaOHDmivLw8FRYW6r777tPRo0etl2Sqvb1dnZ2dEa+PQCCg4uLiq/L1UV9fr+zsbE2ZMkUPPPCATp48ab2kuOrp6ZEkZWZmSpKam5s1MDAQ8XqYOnWqJk6cOKpfD188D5975ZVXlJWVpWnTpqm6ulqnT5+2WN4ljbibkX7Rp59+qvPnzysnJyfi8ZycHH300UdGq7JRXFysLVu2aMqUKero6NDTTz+tO+64Q4cPH1ZaWpr18kx0dnZK0pCvj8+fu1qUl5dryZIlKigoUFtbm3784x+roqJCjY2NSk5Otl5ezA0ODmrdunWaM2eOpk2bJunC6yE1NVUZGRkR+47m18NQ50GS7r33Xk2aNEl5eXk6dOiQHnvsMbW0tOjNN980XG2kER8g/F1FRUX4zzNmzFBxcbEmTZqk3/zmN1q5cqXhyjAS3H333eE/T58+XTNmzNDkyZNVX1+vBQsWGK4sPiorK3X48OGr4vugX+ZS52H16tXhP0+fPl25ublasGCB2traNHny5OFe5pBG/JfgsrKylJycfNG7WLq6uhQMBo1WNTJkZGTopptuUmtrq/VSzHz+GuD1cbHCwkJlZWWNytfH2rVr9fbbb+vdd9+N+PUtwWBQZ8+eVXd3d8T+o/X1cKnzMJTi4mJJGlGvhxEfoNTUVM2cOVN1dXXhxwYHB1VXV6eSkhLDldk7deqU2tralJuba70UMwUFBQoGgxGvj1AopP3791/1r4+PP/5YJ0+eHFWvD+ec1q5dq+3bt+udd95RQUFBxPMzZ85USkpKxOuhpaVFR48eHVWvh8udh6EcPHhQkkbW68H6XRBfxWuvveb8fr/bsmWL++Mf/+hWr17tMjIyXGdnp/XShtUPf/hDV19f79rb293vf/97V1pa6rKystyJEyeslxZXvb297oMPPnAffPCBk+Q2btzoPvjgA/fXv/7VOefcz3/+c5eRkeF27tzpDh065BYtWuQKCgrcZ599Zrzy2Pqy89Db2+seeeQR19jY6Nrb292ePXvct771LXfjjTe6M2fOWC89Zh544AEXCARcfX296+joCG+nT58O77NmzRo3ceJE984777gDBw64kpISV1JSYrjq2LvceWhtbXU/+clP3IEDB1x7e7vbuXOnKywsdHPnzjVeeaSECJBzzj3//PNu4sSJLjU11c2ePds1NTVZL2nYLVu2zOXm5rrU1FT39a9/3S1btsy1trZaLyvu3n33XSfpom358uXOuQtvxX7iiSdcTk6O8/v9bsGCBa6lpcV20XHwZefh9OnTbuHChe766693KSkpbtKkSW7VqlWj7h9pQ/33S3KbN28O7/PZZ5+5H/zgB+5rX/uau+aaa9xdd93lOjo67BYdB5c7D0ePHnVz5851mZmZzu/3uxtuuMH96Ec/cj09PbYL/wJ+HQMAwMSI/x4QAGB0IkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM/D/F8HkaOsIwlgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = train_set[84][0]\n",
    "plt.imshow(img.reshape(28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1233365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7cf526383cb0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = img.to(device).reshape(1, 784)\n",
    "out = best_model(img)\n",
    "plt.imshow(out.reshape(28, 28).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7969ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoencoder-mnist.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43msolver\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_model,\n\u001b[1;32m      5\u001b[0m }, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solver' is not defined"
     ]
    }
   ],
   "source": [
    "f = \"autoencoder-mnist.pth\"\n",
    "torch.save({\n",
    "    \"solver\": solver,\n",
    "    \"checkpoint\": best_model,\n",
    "}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f81cb50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (encoder): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Linear(in_features=256, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=512, out_features=784, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_data = torch.load(f)\n",
    "best_model = loaded_model_data[\"checkpoint\"]\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd85710",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m out \u001b[38;5;241m=\u001b[39m best_model(img)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1, 784, device=device)\n",
    "out = best_model(img)\n",
    "plt.imshow(out.reshape(28, 28).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8c740a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7cf56e3aa5a0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
